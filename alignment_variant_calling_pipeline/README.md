# T2T-CHM13v2.0 Alignment and Variant Calling Pipeline

This directory contains the workflows (as WDLs) used to perform alignment and variant calling on the T2T-CHM13v2.0 reference. The entire pipeline was run on the AnVIL cloud computing platform. For our paper (<a href="https://doi.org/10.1101/2022.12.01.518724" target="_blank">The complete sequence of a human Y chromosome</a>), we performed alignment and variant calling for all 3202 samples from the 1000 Genomes Project (1KGP) as well as 279 samples from the Simons Genome Diversity Project (SGDP). Alignments and variant calls (as well as statistics, metadata, and other resources) for both of these datasets are available from our <a href="https://anvil.terra.bio/#workspaces/anvil-datastorage/AnVIL_T2T_CHRY" target="_blank">public T2T-chrY AnVIL repository</a>.

Described below is each workflow used in the pipeline, listed in order, along with the expected inputs and outputs for each.

## 1. `prepare_reference` Workflow
### Inputs
* This should all be set-up properly, assuming the workspace was simply copied.

### Outputs
* The output files should be output to a directory in the `Files` section of the `Data` tab. You can copy these to the `Workspace Data` section after running so as to more easily access them later if you want to.

## 2. `t2t_realignment` Workflow
- Before you run this workflow with the SGDP data, you will want to create a data table for the SGDP samples (similar to the `CHM13_HG002_Y_sample` data table). At the beginning of the pipeline, you'll only need the `sample_id`, `sex`, and `read_1_fastq` and `read_2_fastq` columns filled out.
- You should run this workflow with a data table input (either the original `CHM13_HG002_Y_sample` data table for 1KGP, or the data table you made for SGDP).
- You'll have to run this workflow separately for XX and XY samples. You can select a subset of samples with the `SELECT DATA` button. (HINT: you can use the same subset of samples later by selecting `Choose existing sets of <Data Table>` after clicking `SELECT DATA`).

### Inputs
- `bwaIndexTar`: Output of Step 1. Will be either XX or XY specific. Either an absolute file path, or the path from Workspace, if you moved the files there (something like `workspace.chm13v2_XX_bwaIndex`)
- `inputFastq1` and `inputFastq2`: The appropriate columns from your chosen Data Table. For the 1KGP Data Table, `this.read_1_fastq` and `this.read_2_fastq`.
- `sampleName`: The appropriate columns from your chosen Data Table. For the 1KGP Data Table `this.CHM13_HG002_Y_sample_id`.
- `targetRef`: Output of Step 1. Will be either XX or XY specific. Again, this can always either be an absolute file path, or the path from Workspace, if you moved the files there.

### Outputs
- The output files can all be written to the input Data Table in the appropriate columns. For the 1KGP data, you should not need to change any of the column names.

## 3. `haplotype_calling` Workflow
- You should run this workflow with the same data table you used for Step 2.
- As before, you'll have to run this workflow separately for XX and XY samples.

### Inputs
- `cram`, `cramIndex`: Output of Step 2. Use the appropriate columns from the Data Table.
- `fastaDict`, `fastaIndex`, `refFasta`: Output of Step 1. Will be either XX or XY specific.
- `sampleName`, `sex`: The appropriate columns from your Data Table.
- `nonparXbed`,`parXbed`,`parYbed`: These are absolute file paths to files Samantha uploaded. You should not need to change these.

### Outputs
- The output files call all be written to the input Data Table in the appropriate columns. For the 1KGP data, you should not need to change any of the column names.

## 4. Creating sample maps
* As of right now, there is a not a workflow for this step, but you're welcome to create one. I just did this step in the workspace terminal.
* You will need to generate four TSVs that point from each sample to where the following files--generated by Step 3--exist:
	*   `chrX_PAR1_sample_map.tsv`
		* For XY samples, map `sample_id` to `XY_X_PAR_hcVCF_gz` output from Step 3
		* For XX samples, map `sample_id` to `XX_X_hcVCF_gz` output from Step 3
	* `chrX_PAR2_sample_map.tsv`
		* Same as above
	* `chrX_non_PAR_sample_map.tsv`
		* For XY samples, map `sample_id` to `XY_X_non_PAR_hcVCF_gz` output from Step 3
		* For XX samples, map `sample_id` to `XX_X_hcVCF_gz` output from Step 3
	* `chrY_sample_map.tsv`
		* For XY samples, map `sample_id` to `XY_Y_nonPAR_hcVCF_gz` output from Step 3
		* Do not include XX samples

## 5. `generate_genomics_db` Workflow
- You should run this workflow with the `PAR_interval` data table. You shouldn't need to create a new Data Table.

### Inputs
- `chromosome`, `interval`, `marginedStart`, `marginedEnd`,, `regionType`: The appropriate columns from the Data Table.  These should not need to be changed.
- `dbBucket`: The name of your bucket (i.e. the prefix of the sample map file paths).
- `filePath`: The path to the directory containing your four sample map files from Step 4. So the full path to this directory would be `"gs://<dbBucket>/<filePath>"`

### Outputs
- `genomicsDBtar`: The column in the `PAR_interval` data table to store the output to. This **SHOULD** be a new column, for whichever set of samples you chose to run. 

## 6. `interval_calling` Workflow
- You should run this workflow with the `PAR_interval` data table, same as Step 5.

### Inputs
- `chromosome`, `interval`, `marginedStart`, `marginedEnd`, `start`, `end`: The appropriate columns from the Data Table. These should not need to be changed.
- `genomicsDBtar`: The name of the column created in Step 5.
- `refFasta`, `refDict`, `refIndex`: These are absolute file paths to files Samantha uploaded. You should not need to change these.

### Outputs
- `genotypeIntervalVCF`, `genotypedIntervalVCFgz`, `genotypedIntervalVCFtabix`: The columns in the `PAR_interval` data table to store the outputs to. As with Step 5, these **SHOULD** be new columns, for whichever set of samples you chose to run.

## 7. `concat_vcfs_chromosome` Workflow
- You should run this workflow with the `PAR_interval_set` data table. This is a bit different than `PAR_interval`.  Instead, it notes all the intervals in `PAR_interval` belonging to each chromosome. You can run the workflow on a single chromosome at a time, or all chromosomes at once (select `Choose existing sets of PAR_interval_sets`).

### Inputs
- `chromosome`: The appropriate column in the data table. This should not need to be changed.
- `indexes`, `VCFs`: The names of the appropriate columns created in Step 6. You'll have to do `this.PAR_intervals.<column_name>`, as `PAR_interval_set` is a set of multiple `PAR_intervals`.
	- Note: You can used the gzipped VCFs for the `VCFs` input.

### Outputs
- The outputs of running this workflow aren't stored in a data frame, but can be added to the `chromosome` data table in a new column, labeled in a similar way to how you labeled the outputs of Steps 5 and 6.

## 8. `recalibration` Workflow
- You should run this workflow with the `chromosome` data table.

### Inputs
- `chromosome`: The appropriate column in the data table. This should not need to be changed.
- `VCF`: This should the be output of Step 7. You will either need to add the output of Step 7 to a new column in the `chromosome` data table, or use an absolute file path here. If you choose to use an absolute file path, you'll need to run each chromosome separately.
- The rest of the inputs are absolute file paths to files Samantha uploaded. You should not need to change these.

### Outputs
- `recalibratedVCF`, `recalibratedVCFgz`, `recalibratedVCFtabix`: The columns in the `chromosome` data table to store the outputs to. As with Steps 5-7, these **SHOULD** be new columns, for whichever set of samples you chose to run.

## 9. `get_pass_records` Workflow
- You should run this workflow with the `chromosome` data table.

### Inputs
- `inputVCFgz`: The name of the appropriate column created in Step 8.

### Outputs
- `pass_bgzip`, `pass_index`, `pass_stats`, `passVCF`:  The columns in the `chromosome` data table to store the outputs to. As with previous steps, these **SHOULD** be new columns, for whichever set of samples you chose to run.
- 
